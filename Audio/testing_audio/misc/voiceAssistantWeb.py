import os
import sys
import asyncio
import websockets
import json
import base64
from google.cloud import speech
from pathlib import Path
from google.cloud.speech_v1 import RecognitionConfig, StreamingRecognitionConfig, StreamingRecognizeRequest

# Import your existing processing function
from fullDatabaseRetrieval import answer_course_question

class VoiceAssistantProcessor:
    def __init__(self):
        # Speech client setup
        self.speech_client = speech.SpeechClient()
        self.config = RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="en-US",
            enable_automatic_punctuation=True
        )
        self.streaming_config = StreamingRecognitionConfig(
            config=self.config, 
            interim_results=True
        )
        
        # Audio processing state
        self.full_transcript = ""
        self.is_processing = False

    async def process_audio_stream(self, websocket):
        """
        Continuously process audio stream
        Similar to original miniaudio approach
        """
        self.is_processing = True
        self.full_transcript = ""
        
        print("Starting audio processing...")

        try:
            # Create generator for streaming audio
            async def audio_generator():
                while self.is_processing:
                    try:
                        # Receive audio chunk from WebSocket
                        audio_chunk = await websocket.recv()
                        # Convert ArrayBuffer to bytes
                        if isinstance(audio_chunk, str):
                            # Skip JSON control messages
                            try:
                                control_msg = json.loads(audio_chunk)
                                if control_msg.get('command') == 'stop':
                                    break
                                continue
                            except:
                                pass
                        
                        # Process binary audio data
                        yield StreamingRecognizeRequest(audio_content=audio_chunk)
                    except websockets.exceptions.ConnectionClosed:
                        print("WebSocket connection closed")
                        break
                    except Exception as e:
                        print(f"Error in audio generator: {e}")
                        break

            # Streaming recognition
            stream_generator = audio_generator()
            responses = self.speech_client.streaming_recognize(
                self.streaming_config, 
                stream_generator.__aiter__()
            )

            for response in responses:
                if not response.results:
                    continue

                result = response.results[0]
                if not result.alternatives:
                    continue

                transcript = result.alternatives[0].transcript
                
                # Send interim results for real-time display
                await websocket.send(json.dumps({
                    'interim_transcript': transcript,
                    'is_final': result.is_final
                }))

                if result.is_final:
                    self.full_transcript = transcript  # Just use the current complete sentence
                    
                    # Check for exit command
                    if "goodbye butler" in transcript.lower():
                        await websocket.send(json.dumps({
                            'transcript': "Goodbye! I hope I answered your questions.",
                            'response': "Goodbye! I hope I answered your questions.",
                            'command': 'exit'
                        }))
                        break
                        
                    # Process final transcript
                    try:
                        print(f"Processing question: '{self.full_transcript}'")
                        response_text = answer_course_question(self.full_transcript.strip())
                        
                        # Get the audio file that was generated by text_to_speech in answer_course_question
                        audio_file_path = script_dir / "text_to_speech_output.mp3"
                        
                        # Read and encode the audio file for transmission
                        if os.path.exists(audio_file_path):
                            with open(audio_file_path, "rb") as audio_file:
                                audio_data = base64.b64encode(audio_file.read()).decode('utf-8')
                        else:
                            audio_data = None
                        
                        # Send response back to client
                        await websocket.send(json.dumps({
                            'transcript': self.full_transcript,
                            'response': response_text,
                            'audio': audio_data
                        }))
                        
                    except Exception as e:
                        print(f"Error processing response: {e}")
                        await websocket.send(json.dumps({
                            'error': str(e)
                        }))

        except Exception as e:
            print(f"Processing error: {e}")
            await websocket.send(json.dumps({
                'error': str(e)
            }))
        finally:
            self.is_processing = False
            print("Audio processing ended")

# Define the script directory for file paths
script_dir = Path(__file__).resolve().parent

async def voice_assistant_handler(websocket, path):
    """WebSocket handler for voice assistant"""
    processor = VoiceAssistantProcessor()
    
    # Send initial greeting
    await websocket.send(json.dumps({
        'greeting': "Hi! I'm BUtLAR, here to answer any of your BU-related questions. I'm listening..."
    }))
    
    await processor.process_audio_stream(websocket)

async def main():
    # Setup WebSocket server
    server = await websockets.serve(
        voice_assistant_handler, 
        "0.0.0.0", 
        5000
    )
    print("WebSocket server started on ws://0.0.0.0:5000")
    await server.wait_closed()

if __name__ == "__main__":
    asyncio.run(main())